name: Weekly S&P 500 Update

on:
  schedule:
    # At 21:11 UTC every Thursday
    - cron: '52 16 * * 6'

jobs:
  update-sp500:
    name: Run S&P 500 Scraper
    runs-on: ubuntu-latest
    env:
      TZ: Europe/London

    steps:
      # 1) Check out the repo with full history + write access
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      # 2) Set up Python
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3) Install your dependencies
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests yfinance numba lxml

      # 4) Run your scraper
      - name: Run S&P 500 update script
        run: python SP500.py

      # 5) Push updated CSV back to main
      - name: Push updated SP500.csv
        uses: ad-m/github-push-action@v0.6.0
        with:
          # uses the automatically provided GITHUB_TOKEN
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: main
          file_pattern: SP500.csv
          commit_message: "chore: update SP500.csv [skip ci]"
